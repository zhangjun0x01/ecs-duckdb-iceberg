# name: test/sql/cloud/glue/test_direct_keys_glue_no_endpoint_type.test
# description: test integration with iceberg catalog read
# group: [glue]

require-env ICEBERG_AWS_REMOTE_AVAILABLE

require-env AWS_ACCESS_KEY_ID

require-env AWS_SECRET_ACCESS_KEY

require avro

require parquet

require iceberg

require httpfs

require aws


# TODO: re-enable these tests once we know what account has these
#  credentials, and we can grant them access to the glue catalog
mode skip

# test using keys directory
statement ok
CREATE SECRET s1 (
	TYPE S3,
	KEY_ID '${AWS_ACCESS_KEY_ID}',
	SECRET '${AWS_SECRET_ACCESS_KEY}',
	REGION 'us-east-1'
);

statement ok
attach '840140254803:s3tablescatalog/pyiceberg-blog-bucket' as my_datalake (
	TYPE ICEBERG,
	AUTHORIZATION_TYPE 'sigv4',
	ENDPOINT 'glue.us-east-1.amazonaws.com/iceberg'
);

query T nosort tables_1
show all tables;
----

statement ok
SELECT count(*) FROM my_datalake.myblognamespace.lineitem;

statement ok
drop secret s1;

statement ok
detach my_datalake;

mode unskip

# test using assume role
statement ok
CREATE SECRET assume_role_secret (
    TYPE S3,
    PROVIDER credential_chain,
    CHAIN 'sts',
    ASSUME_ROLE_ARN 'arn:aws:iam::840140254803:role/pyiceberg-etl-role',
    REGION 'us-east-1'
);

statement ok
attach '840140254803:s3tablescatalog/pyiceberg-blog-bucket' as my_datalake (
	TYPE ICEBERG,
	AUTHORIZATION_TYPE 'sigv4',
	ENDPOINT 'glue.us-east-1.amazonaws.com/iceberg'
);

query T nosort tables_1
show all tables;
----

statement ok
select count(*) from my_datalake.myblognamespace.lineitem;

statement ok
drop secret assume_role_secret;

statement ok
detach my_datalake

# test using provider credential chain
statement ok
CREATE SECRET (
  TYPE S3,
  PROVIDER credential_chain,
  REGION 'us-east-1'
);

statement ok
attach '840140254803:s3tablescatalog/pyiceberg-blog-bucket' as my_datalake (
	TYPE ICEBERG,
	AUTHORIZATION_TYPE 'sigv4',
	ENDPOINT 'glue.us-east-1.amazonaws.com/iceberg'
);

query T nosort tables_1
show all tables;
----
