# name: test/sql/cloud/glue/test_direct_keys_glue.test
# description: test integration with iceberg catalog read
# group: [glue]

require-env ICEBERG_AWS_REMOTE_AVAILABLE

require-env AWS_ACCESS_KEY_ID

require-env AWS_SECRET_ACCESS_KEY



require parquet

require iceberg

require httpfs

require aws

# TODO: re-enable these tests once we know what account has these
#  credentials, and we can grant them access to the glue catalog
# test using keys directory
mode skip

statement ok
CREATE SECRET s1 (
      TYPE S3,
      KEY_ID '${AWS_ACCESS_KEY_ID}',
      SECRET '${AWS_SECRET_ACCESS_KEY}',
      REGION 'us-east-1'
);

statement ok
attach '840140254803:s3tablescatalog/pyiceberg-blog-bucket' as my_datalake (
    TYPE ICEBERG,
    ENDPOINT_TYPE 'GLUE'
);

query T nosort tables_1
show all tables;
----

statement ok
SELECT count(*) FROM my_datalake.myblognamespace.lineitem;

statement ok
drop secret s1;

statement ok
detach my_datalake;

mode unskip

# test using assume role
statement ok
CREATE SECRET assume_role_secret (
    TYPE S3,
    PROVIDER credential_chain,
    CHAIN 'sts',
    ASSUME_ROLE_ARN 'arn:aws:iam::840140254803:role/pyiceberg-etl-role',
    REGION 'us-east-1'
);

statement ok
attach '840140254803:s3tablescatalog/pyiceberg-blog-bucket' as my_datalake (
    TYPE ICEBERG,
    ENDPOINT_TYPE 'GLUE'
);

# TODO: re-enable verification of this output with output from 101
query I
select count(*) > 5 from (show all tables);
----
1

statement ok
select count(*) from my_datalake.myblognamespace.lineitem;

statement ok
drop secret assume_role_secret;

statement ok
detach my_datalake

# test using provider credential chain
statement ok
CREATE SECRET (
  TYPE S3,
  PROVIDER credential_chain,
  REGION 'us-east-1'
);

statement ok
attach '840140254803:s3tablescatalog/pyiceberg-blog-bucket' as my_datalake (
    TYPE ICEBERG,
    ENDPOINT_TYPE 'GLUE'
);

# TODO: re-enable verification of this output with output from 73
query I
select count(*) > 5 from (show all tables);
----
1

